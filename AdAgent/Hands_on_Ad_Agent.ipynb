{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myrah/AAI2025/blob/dev/AdAgent/Hands_on_Ad_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building an Ad Optimization Agent is an excellent, practical use case for AI agents\\! Since the core functionality will involve complex, multi-step decision-making, the **LangGraph** framework (an extension of LangChain) is ideal for defining the stateful, cyclical workflow.\n",
        "\n",
        "Here is a simplified Python workshop code template using **LangGraph** and **LangChain** components. This example focuses on the agent's decision-making flow rather than connecting to live ad platform APIs, which would be proprietary and outside a workshop's scope.\n",
        "\n",
        "You'll need to install the necessary libraries and set your API key (e.g., for an OpenAI or Anthropic LLM).\n",
        "\n",
        "```bash\n",
        "pip install langgraph langchain langchain_openai pydantic\n",
        "```\n",
        "\n",
        "## Python Workshop Code: Ad Optimization Agent\n",
        "\n",
        "The agent will follow a core decision loop: **Gather Data** $\\rightarrow$ **Analyze** $\\rightarrow$ **Decide Action** $\\rightarrow$ **Execute Tool** $\\rightarrow$ **Repeat/Finish**.\n",
        "\n",
        "### 1\\. Imports and State Definition\n",
        "\n",
        "We define the `AgentState` to hold the data and decision history throughout the graph's execution."
      ],
      "metadata": {
        "id": "BBhYvtTVL1vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langgraph langchain langchain_openai pydantic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_-8O9QrMCpt",
        "outputId": "c83ae48a-8a0f-4afb-c3c9-e1982fb64bb8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.10)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.79)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.37)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langchain_openai, langgraph-prebuilt, langgraph\n",
            "Successfully installed langchain_openai-0.3.35 langgraph-1.0.1 langgraph-checkpoint-3.0.0 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 ormsgpack-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import operator\n",
        "from typing import TypedDict, Annotated, List\n",
        "\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- Environment Setup (Replace with your actual key) ---\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_EDU_API_KEY\")\n",
        "\n",
        "# 1. Define the Agent State\n",
        "# This represents the information passed between nodes in the graph\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our ad optimization agent.\n",
        "    - messages: A list of messages/history.\n",
        "    - campaign_data: The current (simulated) ad campaign metrics.\n",
        "    - next_action: The recommended action from the analysis.\n",
        "    \"\"\"\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    campaign_data: dict\n",
        "    next_action: str\n",
        "\n",
        "# 2. Initialize LLM\n",
        "# We'll use a powerful model for the reasoning engine\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "hY5vVk6hL1vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 2\\. Define Custom Tools\n",
        "\n",
        "We create \"tools\" (Python functions) that the LLM can decide to use to interact with the external world (e.g., ad platform APIs). In a workshop, these are simulated."
      ],
      "metadata": {
        "id": "lpWTXIM_L1vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Simulated Tools for Ad Optimization ---\n",
        "\n",
        "@tool\n",
        "def adjust_bid(campaign_id: str, new_bid_amount: float) -> str:\n",
        "    \"\"\"Adjusts the bid for a specific ad campaign to the new amount.\"\"\"\n",
        "    if new_bid_amount > 5.00:\n",
        "        return f\"Bid for Campaign '{campaign_id}' adjusted to ${new_bid_amount:.2f}. (Simulated: High bid warning!)\"\n",
        "    return f\"Bid for Campaign '{campaign_id}' adjusted to ${new_bid_amount:.2f} successfully.\"\n",
        "\n",
        "@tool\n",
        "def pause_ad_group(ad_group_id: str) -> str:\n",
        "    \"\"\"Pauses an underperforming ad group by its ID.\"\"\"\n",
        "    return f\"Ad Group '{ad_group_id}' paused successfully due to poor performance.\"\n",
        "\n",
        "@tool\n",
        "def request_new_creatives(campaign_id: str) -> str:\n",
        "    \"\"\"Requests new ad creative assets from the creative team.\"\"\"\n",
        "    return f\"New creative request submitted for Campaign '{campaign_id}'. Awaiting design feedback.\"\n",
        "\n",
        "ad_optimization_tools = [adjust_bid, pause_ad_group, request_new_creatives]"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "pnQfdIsfL1vv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 3\\. Define Graph Nodes (Steps)\n",
        "\n",
        "The nodes are the functions that run at each step of the agent's workflow."
      ],
      "metadata": {
        "id": "0CXyMTH7L1vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_campaign_data(state: AgentState) -> dict:\n",
        "    \"\"\"Simulates fetching the latest campaign data.\"\"\"\n",
        "    print(\"--- FETCHING DATA ---\")\n",
        "    # In a real scenario, this would call an Ad API (e.g., Google Ads, Meta)\n",
        "    # This is a fixed, simulated dataset for the workshop\n",
        "    simulated_data = {\n",
        "        \"Campaign-2024-Q4\": {\n",
        "            \"Budget\": 1000, \"Spend\": 850, \"Impressions\": 50000,\n",
        "            \"Clicks\": 500, \"Conversions\": 5, \"CPA\": 170.00, \"Target_CPA\": 50.00,\n",
        "            \"Ad_Groups\": {\n",
        "                \"AG-101\": {\"Status\": \"Active\", \"CPA\": 25.00, \"Bid\": 2.50},\n",
        "                \"AG-102\": {\"Status\": \"Active\", \"CPA\": 450.00, \"Bid\": 3.00} # Poor performer\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    analysis_prompt = (\n",
        "        \"Ad Campaign Data for Optimization:\\n\"\n",
        "        f\"{simulated_data}\\n\\n\"\n",
        "        \"**Optimization Goal:** Reduce overall CPA (Cost Per Acquisition) to be closer to the Target CPA ($50.00) \"\n",
        "        \"and maximize conversions. Analyze the data and recommend the *single best action* \"\n",
        "        \"using one of the provided tools (adjust_bid, pause_ad_group, request_new_creatives). \"\n",
        "        \"Your final output should be ONLY the recommended action as a message for the user, \"\n",
        "        \"or a clear instruction for the next internal step.\"\n",
        "    )\n",
        "\n",
        "    # Prepend the analysis prompt to the messages for the LLM\n",
        "    new_messages = [HumanMessage(content=analysis_prompt)]\n",
        "\n",
        "    return {\"messages\": new_messages, \"campaign_data\": simulated_data}\n",
        "\n",
        "def agent_reasoning(state: AgentState) -> dict:\n",
        "    \"\"\"The LLM reasons and decides the next step (tool call or final answer).\"\"\"\n",
        "    print(\"--- AGENT REASONING ---\")\n",
        "\n",
        "    # Bind the tools to the LLM\n",
        "    llm_with_tools = llm.bind_tools(ad_optimization_tools)\n",
        "\n",
        "    # Define a system prompt to guide the LLM's role\n",
        "    system_prompt = (\n",
        "        \"You are an expert Ad Campaign Optimization Agent. \"\n",
        "        \"Your goal is to analyze the provided campaign data and decide the optimal next action. \"\n",
        "        \"You must use a tool if an optimization is possible. \"\n",
        "        \"If no tool is needed or you have executed a tool, provide a final, concise update.\"\n",
        "    )\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        (\"placeholder\", \"{messages}\")\n",
        "    ])\n",
        "\n",
        "    # Run the LLM to get a decision\n",
        "    chain = prompt | llm_with_tools\n",
        "    response = chain.invoke(state)\n",
        "\n",
        "    # Determine if a tool call was made\n",
        "    if response.tool_calls:\n",
        "        # If a tool is called, the next step is to execute it.\n",
        "        return {\"messages\": [response], \"next_action\": \"call_tool\"}\n",
        "    else:\n",
        "        # If no tool is called, the reasoning is the final response.\n",
        "        return {\"messages\": [response], \"next_action\": \"FINISH\"}\n",
        "\n",
        "\n",
        "def execute_tools(state: AgentState) -> dict:\n",
        "    \"\"\"Executes the tool call(s) decided by the agent_reasoning step.\"\"\"\n",
        "    print(\"--- EXECUTING TOOL ---\")\n",
        "\n",
        "    tool_calls = state[\"messages\"][-1].tool_calls\n",
        "    tool_results = []\n",
        "\n",
        "    # Find and execute the function corresponding to the tool call\n",
        "    for call in tool_calls:\n",
        "        tool_name = call[\"name\"]\n",
        "        tool_args = call[\"args\"]\n",
        "        tool_call_id = call[\"id\"] # Get the tool call ID\n",
        "\n",
        "        # Simple lookup and execution (in a real app, use the ToolExecutor)\n",
        "        tool_to_run = next(\n",
        "            (t for t in ad_optimization_tools if t.name == tool_name), None\n",
        "        )\n",
        "\n",
        "        if tool_to_run:\n",
        "            try:\n",
        "                result = tool_to_run.invoke(tool_args)\n",
        "                # Format the tool result as a ToolMessage\n",
        "                tool_results.append({\n",
        "                    \"type\": \"tool_output\",\n",
        "                    \"tool_call_id\": tool_call_id, # Include the tool call ID\n",
        "                    \"content\": result\n",
        "                })\n",
        "            except Exception as e:\n",
        "                 # Handle tool execution errors and return an error message\n",
        "                 tool_results.append({\n",
        "                    \"type\": \"tool_output\",\n",
        "                    \"tool_call_id\": tool_call_id, # Include the tool call ID\n",
        "                    \"content\": f\"Error executing tool {tool_name}: {e}\"\n",
        "                })\n",
        "\n",
        "\n",
        "    # Add tool results to the state for the LLM to process next\n",
        "    # Need to format the tool results into a list of BaseMessage\n",
        "    tool_messages = [HumanMessage(content=str(r), name=\"tool_execution\") for r in tool_results]\n",
        "\n",
        "    return {\"messages\": tool_messages}\n",
        "\n",
        "def decide_next_step(state: AgentState) -> str:\n",
        "    \"\"\"Conditional edge: decides whether to continue analysis or finish.\"\"\"\n",
        "    print(f\"--- DECIDING NEXT STEP ---\")\n",
        "    print(f\"state['next_action']: {state.get('next_action')}\") # Use .get() for safety\n",
        "\n",
        "    next_action = state.get(\"next_action\")\n",
        "\n",
        "    if next_action == \"call_tool\":\n",
        "        print(\"Returning 'call_tool'\") # Corrected return value\n",
        "        return \"call_tool\"\n",
        "    elif next_action == \"FINISH\":\n",
        "        print(\"Returning 'end'\")\n",
        "        return \"end\"\n",
        "    else:\n",
        "        # After tool execution, go back to reasoning to summarize the result\n",
        "        print(\"Returning 'agent_reasoning'\")\n",
        "        return \"agent_reasoning\""
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "id": "RWQLrfocL1vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "def fetch_campaign_data(state: AgentState) -> dict:\n",
        "    \"\"\"Simulates fetching the latest campaign data.\"\"\"\n",
        "    print(\"--- FETCHING DATA ---\")\n",
        "    # In a real scenario, this would call an Ad API (e.g., Google Ads, Meta)\n",
        "    # This is a fixed, simulated dataset for the workshop\n",
        "    simulated_data = {\n",
        "        \"Campaign-2024-Q4\": {\n",
        "            \"Budget\": 1000, \"Spend\": 850, \"Impressions\": 50000,\n",
        "            \"Clicks\": 500, \"Conversions\": 5, \"CPA\": 170.00, \"Target_CPA\": 50.00,\n",
        "            \"Ad_Groups\": {\n",
        "                \"AG-101\": {\"Status\": \"Active\", \"CPA\": 25.00, \"Bid\": 2.50},\n",
        "                \"AG-102\": {\"Status\": \"Active\", \"CPA\": 450.00, \"Bid\": 3.00} # Poor performer\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    analysis_prompt = (\n",
        "        \"Ad Campaign Data for Optimization:\\n\"\n",
        "        f\"{simulated_data}\\n\\n\"\n",
        "        \"**Optimization Goal:** Reduce overall CPA (Cost Per Acquisition) to be closer to the Target CPA ($50.00) \"\n",
        "        \"and maximize conversions. Analyze the data and recommend the *single best action* \"\n",
        "        \"using one of the provided tools (adjust_bid, pause_ad_group, request_new_creatives). \"\n",
        "        \"Your final output should be ONLY the recommended action as a message for the user, \"\n",
        "        \"or a clear instruction for the next internal step.\"\n",
        "    )\n",
        "\n",
        "    # Prepend the analysis prompt to the messages for the LLM\n",
        "    new_messages = [HumanMessage(content=analysis_prompt)]\n",
        "\n",
        "    return {\"messages\": new_messages, \"campaign_data\": simulated_data}\n",
        "\n",
        "def agent_reasoning(state: AgentState) -> dict:\n",
        "    \"\"\"The LLM reasons and decides the next step (tool call or final answer).\"\"\"\n",
        "    print(\"--- AGENT REASONING ---\")\n",
        "\n",
        "    # Bind the tools to the LLM\n",
        "    llm_with_tools = llm.bind_tools(ad_optimization_tools)\n",
        "\n",
        "    # Define a system prompt to guide the LLM's role\n",
        "    system_prompt = (\n",
        "        \"You are an expert Ad Campaign Optimization Agent. \"\n",
        "        \"Your goal is to analyze the provided campaign data and decide the optimal next action. \"\n",
        "        \"You must use a tool if an optimization is possible. \"\n",
        "        \"If no tool is needed or you have executed a tool, provide a final, concise update.\"\n",
        "    )\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_prompt),\n",
        "        (\"placeholder\", \"{messages}\")\n",
        "    ])\n",
        "\n",
        "    # Run the LLM to get a decision\n",
        "    chain = prompt | llm_with_tools\n",
        "    response = chain.invoke(state)\n",
        "\n",
        "    # Determine if a tool call was made\n",
        "    if response.tool_calls:\n",
        "        # If a tool is called, the next step is to execute it.\n",
        "        return {\"messages\": [response], \"next_action\": \"call_tool\"}\n",
        "    else:\n",
        "        # If no tool is called, the reasoning is the final response.\n",
        "        return {\"messages\": [response], \"next_action\": \"FINISH\"}\n",
        "\n",
        "\n",
        "def execute_tools(state: AgentState) -> dict:\n",
        "    \"\"\"Executes the tool call(s) decided by the agent_reasoning step.\"\"\"\n",
        "    print(\"--- EXECUTING TOOL ---\")\n",
        "\n",
        "    tool_calls = state[\"messages\"][-1].tool_calls\n",
        "    tool_results = []\n",
        "\n",
        "    # Find and execute the function corresponding to the tool call\n",
        "    for call in tool_calls:\n",
        "        tool_name = call[\"name\"]\n",
        "        tool_args = call[\"args\"]\n",
        "        tool_call_id = call[\"id\"] # Get the tool call ID\n",
        "\n",
        "        # Simple lookup and execution (in a real app, use the ToolExecutor)\n",
        "        tool_to_run = next(\n",
        "            (t for t in ad_optimization_tools if t.name == tool_name), None\n",
        "        )\n",
        "\n",
        "        if tool_to_run:\n",
        "            try:\n",
        "                result = tool_to_run.invoke(tool_args)\n",
        "                # Format the tool result as a ToolMessage\n",
        "                tool_results.append(ToolMessage(\n",
        "                    content=result,\n",
        "                    tool_call_id=tool_call_id # Include the tool call ID\n",
        "                ))\n",
        "            except Exception as e:\n",
        "                 # Handle tool execution errors and return an error message\n",
        "                 tool_results.append(ToolMessage(\n",
        "                    content=f\"Error executing tool {tool_name}: {e}\",\n",
        "                    tool_call_id=tool_call_id # Include the tool call ID\n",
        "                ))\n",
        "\n",
        "\n",
        "    # Add tool results to the state for the LLM to process next\n",
        "    return {\"messages\": tool_results}\n",
        "\n",
        "def decide_next_step(state: AgentState) -> str:\n",
        "    \"\"\"Conditional edge: decides whether to continue analysis or finish.\"\"\"\n",
        "    print(f\"--- DECIDING NEXT STEP ---\")\n",
        "    print(f\"state['next_action']: {state.get('next_action')}\") # Use .get() for safety\n",
        "\n",
        "    next_action = state.get(\"next_action\")\n",
        "\n",
        "    if next_action == \"call_tool\":\n",
        "        print(\"Returning 'call_tool'\") # Corrected return value\n",
        "        return \"call_tool\"\n",
        "    elif next_action == \"FINISH\":\n",
        "        print(\"Returning 'end'\")\n",
        "        return \"end\"\n",
        "    else:\n",
        "        # After tool execution, go back to reasoning to summarize the result\n",
        "        print(\"Returning 'agent_reasoning'\")\n",
        "        return \"agent_reasoning\""
      ],
      "metadata": {
        "id": "mq0w9e4-H-3-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "### 4\\. Build and Run the Graph\n",
        "\n",
        "We define the flow using LangGraph's `StateGraph`."
      ],
      "metadata": {
        "id": "9k5ZVCWgL1vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Build the LangGraph Workflow\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"fetch_data\", fetch_campaign_data)\n",
        "workflow.add_node(\"agent_reasoning\", agent_reasoning)\n",
        "workflow.add_node(\"execute_tools\", execute_tools)\n",
        "\n",
        "# Set the start point\n",
        "workflow.set_entry_point(\"fetch_data\")\n",
        "\n",
        "# Add edges\n",
        "# From fetch_data, always go to reasoning\n",
        "workflow.add_edge(\"fetch_data\", \"agent_reasoning\")\n",
        "\n",
        "# Conditional edge from reasoning to decide if it's a tool call or the end\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent_reasoning\",\n",
        "    decide_next_step,\n",
        "    {\"call_tool\": \"execute_tools\", \"end\": END}\n",
        ")\n",
        "\n",
        "# After executing a tool, cycle back to reasoning to formulate a final summary\n",
        "workflow.add_edge(\"execute_tools\", \"agent_reasoning\")\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# 6. Run the Agent\n",
        "print(\"--- STARTING AD OPTIMIZATION AGENT RUN ---\")\n",
        "\n",
        "# The agent runs autonomously until it hits the END node\n",
        "# It starts by fetching data, which primes the first message.\n",
        "final_state = app.invoke(\n",
        "    {\"messages\": [], \"campaign_data\": {}, \"next_action\": \"start\"},\n",
        "    config={\"recursion_limit\": 50}\n",
        ")\n",
        "\n",
        "# 7. Print Final Result\n",
        "final_message = final_state[\"messages\"][-1].content\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"AGENT FINAL RECOMMENDATION & SUMMARY:\")\n",
        "print(final_message)\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Optional: Visualize the graph (requires pydot/graphviz)\n",
        "# from IPython.display import Image\n",
        "# Image(app.get_graph().draw_png())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING AD OPTIMIZATION AGENT RUN ---\n",
            "--- FETCHING DATA ---\n",
            "--- AGENT REASONING ---\n",
            "--- DECIDING NEXT STEP ---\n",
            "state['next_action']: call_tool\n",
            "Returning 'call_tool'\n",
            "--- EXECUTING TOOL ---\n",
            "--- AGENT REASONING ---\n",
            "--- DECIDING NEXT STEP ---\n",
            "state['next_action']: FINISH\n",
            "Returning 'end'\n",
            "\n",
            "==================================================\n",
            "AGENT FINAL RECOMMENDATION & SUMMARY:\n",
            "Ad Group 'AG-102' has been paused due to poor performance.\n",
            "==================================================\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEGUtGpHL1vw",
        "outputId": "e819e583-eac4-4316-8b09-2519e58993b4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----\n",
        "\n",
        "The video provided below demonstrates building a more advanced research agent using LangChain and LangGraph, offering a great visual example of the framework's capabilities.\n",
        "\n",
        "[Python Advanced AI Agent Tutorial - LangGraph, LangChain, Firecrawl & More\\!](https://www.youtube.com/watch?v=xekw62yQu14&pp=0gcJCf8Ao7VqN5tD) This video is relevant as it provides a practical tutorial on building a complex, multi-step AI agent using the LangGraph and LangChain frameworks, which are central to the workshop code."
      ],
      "metadata": {
        "id": "uxtJ7rDwL1vw"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}