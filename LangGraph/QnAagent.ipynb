{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbHoWBNi4iL4uxxJSPpQIy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/myrah/AAI2025/blob/dev/LangGraph/QnAagent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qUcy23Yf_Xu9"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Set your OpenAI API key (from https://platform.openai.com/api-keys)\n",
        "api_key=userdata.get(\"OPENAI_EDU_API_KEY\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key  # optional but recommended\n",
        "\n",
        "# --- Setup the LLM ---\n",
        "model = ChatOpenAI(\n",
        "    model=\"gpt-4o\",        # or \"gpt-4o-mini\", \"gpt-4-turbo\", etc.\n",
        "    temperature=0.7        # optional, controls randomness\n",
        ")\n",
        "\n",
        "# --- Setup the Embedding model ---\n",
        "embedding = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-large\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "#Load the laptop product pricing CSV into a Pandas dataframe.\n",
        "product_pricing_df = pd.read_csv(\"Laptop pricing.csv\")\n",
        "print(product_pricing_df)\n",
        "\n",
        "@tool\n",
        "def get_laptop_price(laptop_name:str) -> int :\n",
        "    \"\"\"\n",
        "    This function returns the price of a laptop, given its name as input.\n",
        "    It performs a substring match between the input name and the laptop name.\n",
        "    If a match is found, it returns the pricxe of the laptop.\n",
        "    If there is NO match found, it returns -1\n",
        "    \"\"\"\n",
        "\n",
        "    #Filter Dataframe for matching names\n",
        "    match_records_df = product_pricing_df[\n",
        "                        product_pricing_df[\"Name\"].str.contains(\n",
        "                                                \"^\" + laptop_name, case=False)\n",
        "                        ]\n",
        "    #Check if a record was found, if not return -1\n",
        "    if len(match_records_df) == 0 :\n",
        "        return -1\n",
        "    else:\n",
        "        return match_records_df[\"Price\"].iloc[0]\n",
        "\n",
        "#Test the tool. Before running the test, comment the @tool annotation\n",
        "#print(get_laptop_price(\"alpha\"))\n",
        "#print(get_laptop_price(\"testing\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11D1tfjcCscS",
        "outputId": "a4794da6-362e-4606-f4f5-0e0cb52f57cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            Name  Price  ShippingDays\n",
            "0  AlphaBook Pro   1499             2\n",
            "1     GammaAir X   1399             7\n",
            "2  SpectraBook S   2499             7\n",
            "3   OmegaPro G17   2199            14\n",
            "4  NanoEdge Flex   1699             2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langgraph\n",
        "!pip install --upgrade --quiet  pypdf\n",
        "!pip install --upgrade --quiet  langchain-chroma\n",
        "\n",
        "__import__('pysqlite3')\n",
        "import sys\n",
        "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
        "\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Load, chunk and index the contents of the product featuers document.\n",
        "loader=PyPDFLoader(\"Laptop product descriptions.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=256)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "#Create a vector store with Chroma\n",
        "prod_feature_store = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding\n",
        ")\n",
        "\n",
        "get_product_features = create_retriever_tool(\n",
        "    prod_feature_store.as_retriever(search_kwargs={\"k\": 1}),\n",
        "    name=\"Get_Product_Features\",\n",
        "    description=\"\"\"\n",
        "    This store contains details about Laptops. It lists the available laptops\n",
        "    and their features including CPU, memory, storage, design and advantages\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "#Test the product feature store\n",
        "#print(prod_feature_store.as_retriever().invoke(\"Tell me about the AlphaBook Pro\") )"
      ],
      "metadata": {
        "id": "Khh0bZxBDaRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages import AIMessage,HumanMessage,SystemMessage\n",
        "\n",
        "#Create a System prompt to provide a persona to the chatbot\n",
        "system_prompt = SystemMessage(\"\"\"\n",
        "    You are professional chatbot that answers questions about laptops sold by your company.\n",
        "    To answer questions about laptops, you will ONLY use the available tools and NOT your own memory.\n",
        "    You will handle small talk and greetings by producing professional responses.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "#Create a list of tools available\n",
        "tools = [get_laptop_price, get_product_features]\n",
        "\n",
        "#Create memory across questions in a conversation (conversation memory)\n",
        "checkpointer=MemorySaver()\n",
        "\n",
        "#Create a Product QnA Agent. This is actual a graph in langGraph\n",
        "product_QnA_agent=create_react_agent(\n",
        "                                model=model, #LLM to use\n",
        "                                tools=tools, #List of tools to use\n",
        "                                debug=False, #Debugging turned on if needed\n",
        "                                checkpointer=checkpointer #For conversation memory\n",
        ")"
      ],
      "metadata": {
        "id": "15XhMsK3EaXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "effdc805",
        "outputId": "decc3ff9-0750-44c3-f031-2645673a190e"
      },
      "source": [
        "# Example of how to invoke the agent\n",
        "# Replace the question with your query about laptops\n",
        "response = product_QnA_agent.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What is the price of AlphaBook Pro?\")]},\n",
        "    config={\"configurable\": {\"thread_id\": \"some-thread-id\"}} # Replace with a unique thread_id for each conversation\n",
        ")\n",
        "\n",
        "# Print the response from the agent\n",
        "print(response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [HumanMessage(content='What is the price of AlphaBook Pro?', additional_kwargs={}, response_metadata={}, id='c5ad54a3-ca64-49bc-9b52-a21adeb6abc9'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BvBwrswo07ZvYvQeRHVUotne', 'function': {'arguments': '{\"laptop_name\":\"AlphaBook Pro\"}', 'name': 'get_laptop_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 159, 'total_tokens': 179, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_1827dd0c55', 'id': 'chatcmpl-CO7KwSdL5W87g40f59XPyGpu66MvM', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--ba246df9-4674-404f-a697-944b4526f71d-0', tool_calls=[{'name': 'get_laptop_price', 'args': {'laptop_name': 'AlphaBook Pro'}, 'id': 'call_BvBwrswo07ZvYvQeRHVUotne', 'type': 'tool_call'}], usage_metadata={'input_tokens': 159, 'output_tokens': 20, 'total_tokens': 179, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='1499', name='get_laptop_price', id='225f7258-4ea3-4efc-ac1f-b9373020e6ea', tool_call_id='call_BvBwrswo07ZvYvQeRHVUotne'), AIMessage(content='The price of the AlphaBook Pro is $1499.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 191, 'total_tokens': 204, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_1827dd0c55', 'id': 'chatcmpl-CO7KyDXXrJ6kNCvjBLJ3DrM3kgleL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e9ccaedf-fcd1-4b96-8858-f5c485bfc65d-0', usage_metadata={'input_tokens': 191, 'output_tokens': 13, 'total_tokens': 204, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup chatbot\n",
        "import uuid\n",
        "#To maintain memory, each request should be in the context of a thread.\n",
        "#Each user conversation will use a separate thread ID\n",
        "config = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\n",
        "\n",
        "#Test the agent with an input\n",
        "inputs = {\"messages\":[\n",
        "                HumanMessage(\"What are the features and pricing for GammaAir?\")\n",
        "            ]}\n",
        "\n",
        "#Use streaming to print responses as the agent  does the work.\n",
        "#This is an alternate way to stream agent responses without waiting for the agent to finish\n",
        "for stream in product_QnA_agent.stream(inputs, config, stream_mode=\"values\"):\n",
        "    message=stream[\"messages\"][-1]\n",
        "    if isinstance(message, tuple):\n",
        "        print(message)\n",
        "    else:\n",
        "        message.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f4L5VPSE7Z6",
        "outputId": "121a8430-87ca-45f3-8b07-567ef9cea027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What are the features and pricing for GammaAir?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Get_Product_Features (call_cE1LTtb9UJDzIVfxig1n5jbU)\n",
            " Call ID: call_cE1LTtb9UJDzIVfxig1n5jbU\n",
            "  Args:\n",
            "    query: GammaAir\n",
            "  get_laptop_price (call_jOucP9q0JBUT14BDJckvNDta)\n",
            " Call ID: call_jOucP9q0JBUT14BDJckvNDta\n",
            "  Args:\n",
            "    laptop_name: GammaAir\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: get_laptop_price\n",
            "\n",
            "1399\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The GammaAir X is a laptop that combines the following features:\n",
            "\n",
            "- **Processor**: AMD Ryzen 7\n",
            "- **Memory**: 32GB of DDR4 RAM\n",
            "- **Storage**: 512GB NVMe SSD\n",
            "- **Design**: Thin and light form factor, perfect for users who need high performance in a portable design\n",
            "\n",
            "The price for the GammaAir X is $1,399.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "#Send a sequence of messages to chatbot and get its response\n",
        "#This simulates the conversation between the user and the Agentic chatbot\n",
        "user_inputs = [\n",
        "    \"Hello\",\n",
        "    \"I am looking to buy a laptop\",\n",
        "    \"Give me a list of available laptop names\",\n",
        "    \"Tell me about the features of  SpectraBook\",\n",
        "    \"How much does it cost?\",\n",
        "    \"Give me similar information about OmegaPro\",\n",
        "    \"What info do you have on AcmeRight ?\",\n",
        "    \"Thanks for the help\"\n",
        "]\n",
        "\n",
        "#Create a new thread\n",
        "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
        "\n",
        "for input in user_inputs:\n",
        "    print(f\"----------------------------------------\\nUSER : {input}\")\n",
        "    #Format the user message\n",
        "    user_message = {\"messages\":[HumanMessage(input)]}\n",
        "    #Get response from the agent\n",
        "    ai_response = product_QnA_agent.invoke(user_message,config=config)\n",
        "    #Print the response\n",
        "    print(f\"AGENT : {ai_response['messages'][-1].content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOixqoRaFAXR",
        "outputId": "5f1a080e-97a3-4793-a79a-055db3c5edd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "USER : Hello\n",
            "AGENT : Hello! How can I assist you today?\n",
            "----------------------------------------\n",
            "USER : I am looking to buy a laptop\n",
            "AGENT : Great! I can help you with that. Are there specific features or specifications you're looking for in a laptop? For example, CPU type, memory size, storage capacity, or any particular design features? Let me know your preferences so I can provide more tailored recommendations.\n",
            "----------------------------------------\n",
            "USER : Give me a list of available laptop names\n",
            "AGENT : Here is a list of available laptops:\n",
            "\n",
            "1. **AlphaBook Pro**\n",
            "   - 12th Gen Intel i7 processor, 16GB DDR4 RAM, 1TB SSD.\n",
            "\n",
            "2. **GammaAir X**\n",
            "   - AMD Ryzen 7 processor, 32GB DDR4 RAM, 512GB NVMe SSD.\n",
            "\n",
            "3. **SpectraBook S**\n",
            "   - Intel Core i9 processor, 64GB RAM, 2TB SSD.\n",
            "\n",
            "4. **OmegaPro G17**\n",
            "   - Ryzen 9 5900HX CPU, 32GB RAM, 1TB SSD.\n",
            "\n",
            "5. **NanoEdge Flex**\n",
            "\n",
            "Let me know if you need more details about any of these laptops or if you want to know their prices!\n",
            "----------------------------------------\n",
            "USER : Tell me about the features of  SpectraBook\n",
            "AGENT : The **SpectraBook S** is designed for power users and comes with the following features:\n",
            "\n",
            "- **Processor:** Intel Core i9\n",
            "- **Memory:** 64GB RAM\n",
            "- **Storage:** 2TB SSD\n",
            "\n",
            "This workstation-class laptop is perfect for intensive tasks like video editing and 3D rendering, making it ideal for professionals who require high performance and substantial storage capacity. Let me know if you need more information or if you're interested in its pricing!\n",
            "----------------------------------------\n",
            "USER : How much does it cost?\n",
            "AGENT : The SpectraBook S is priced at $2,499. If you have any other questions or need further assistance, feel free to ask!\n",
            "----------------------------------------\n",
            "USER : Give me similar information about OmegaPro\n",
            "AGENT : The **OmegaPro G17** is a gaming powerhouse with the following features:\n",
            "\n",
            "- **Processor:** Ryzen 9 5900HX CPU\n",
            "- **Memory:** 32GB RAM\n",
            "- **Storage:** 1TB SSD\n",
            "- **Display:** 17-inch display with a high refresh rate\n",
            "- **Graphics:** Powerful graphics card for the best gaming experience\n",
            "\n",
            "The OmegaPro G17 is designed specifically for gamers who seek high performance and immersive visuals.\n",
            "\n",
            "The price for the OmegaPro G17 is $2,199.\n",
            "\n",
            "If you have more questions or need further assistance, feel free to ask!\n",
            "----------------------------------------\n",
            "USER : What info do you have on AcmeRight ?\n",
            "AGENT : It seems I don't have any information on a laptop named \"AcmeRight.\" If you have any other queries or need information on a different laptop, please let me know!\n",
            "----------------------------------------\n",
            "USER : Thanks for the help\n",
            "AGENT : You're welcome! If you have any more questions in the future or need further assistance, feel free to reach out. Have a great day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#conversation memory by user\n",
        "def execute_prompt(user, config, prompt):\n",
        "    inputs = {\"messages\":[(\"user\",prompt)]}\n",
        "    ai_response = product_QnA_agent.invoke(inputs,config=config)\n",
        "    print(f\"\\n{user}: {ai_response['messages'][-1].content}\")\n",
        "\n",
        "#Create different session threads for 2 users\n",
        "config_1 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
        "config_2 = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
        "\n",
        "#Test both threads\n",
        "execute_prompt(\"USER 1\", config_1, \"Tell me about the features of  SpectraBook\")\n",
        "execute_prompt(\"USER 2\", config_2, \"Tell me about the features of  GammaAir\")\n",
        "execute_prompt(\"USER 1\", config_1, \"What is its price ?\")\n",
        "execute_prompt(\"USER 2\", config_2, \"What is its price ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5aCLLciQFPTa",
        "outputId": "ee6e20a0-8156-46f2-adb7-52a83dc054ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'uuid' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-539463435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Create different session threads for 2 users\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mconfig_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"configurable\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"thread_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mconfig_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"configurable\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"thread_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'uuid' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Load the laptop product orders CSV into a Pandas dataframe.\n",
        "product_orders_df = pd.read_csv(\"Laptop Orders.csv\")\n",
        "print(product_orders_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCmB4ZKRH5iQ",
        "outputId": "5c2da4f7-972f-4eb4-ecb5-b6982b51f984"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Order ID Product Ordered  Quantity Ordered Delivery Date\n",
            "0  ORD-8276   SpectraBook S                 3    2024-10-16\n",
            "1  ORD-6948    OmegaPro G17                 3    2024-10-25\n",
            "2  ORD-7311   NanoEdge Flex                 2    2024-10-19\n",
            "3  ORD-4633    OmegaPro G17                 2    2024-10-15\n",
            "4  ORD-2050      GammaAir X                 2    2024-10-26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeeece02",
        "outputId": "75025c85-105a-42b4-976f-e604c2d6d2e2"
      },
      "source": [
        "!pip install --upgrade --quiet langchain-openai"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/449.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0d73b90",
        "outputId": "c53eae8b-cbb6-445e-c75b-2bd2bf647852"
      },
      "source": [
        "!pip install --upgrade --quiet langgraph"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def get_order_details(order_id:str) -> str :\n",
        "    \"\"\"\n",
        "    This function returns details about a laptop order, given an order ID\n",
        "    It performs an exact match between the input order id and available order ids\n",
        "    If a match is found, it returns products (laptops) ordered, quantity ordered and delivery date.\n",
        "    If there is NO match found, it returns -1\n",
        "    \"\"\"\n",
        "    #Filter Dataframe for order ID\n",
        "    match_order_df = product_orders_df[\n",
        "                        product_orders_df[\"Order ID\"] == order_id ]\n",
        "\n",
        "    #Check if a record was found, if not return -1\n",
        "    if len(match_order_df) == 0 :\n",
        "        return -1\n",
        "    else:\n",
        "        return match_order_df.iloc[0].to_dict()\n",
        "\n",
        "#Test the tool. Before running the test, comment the @tool annotation\n",
        "#print(get_order_details(\"ORD-6948\"))\n",
        "#print(get_order_details(\"ORD-9999\"))\n",
        "\n",
        "@tool\n",
        "def update_quantity(order_id:str, new_quantity:int) -> bool :\n",
        "    \"\"\"\n",
        "    This function updates the quantity of products ( laptops ) ordered for a given order Id.\n",
        "    It there are no matching orders, it returns False.\n",
        "    \"\"\"\n",
        "    #Find if matching record exists\n",
        "    match_order_df = product_orders_df[\n",
        "                        product_orders_df[\"Order ID\"] == order_id ]\n",
        "\n",
        "    #Check if a record was found, if not return -1\n",
        "    if len(match_order_df) == 0 :\n",
        "        return -1\n",
        "    else:\n",
        "        product_orders_df.loc[\n",
        "            product_orders_df[\"Order ID\"] == order_id,\n",
        "                \"Quantity Ordered\"] = new_quantity\n",
        "        return True\n",
        "\n",
        "#Test the tool. Before running the test, comment the @tool annotation\n",
        "#print(get_order_details(\"ORD-6948\"))\n",
        "#print(update_quantity(\"ORD-6948\", 1))\n",
        "#print(get_order_details(\"ORD-6948\"))\n",
        "#print(update_quantity(\"ORD-9999\",2))\n",
        "#print(product_orders_df)"
      ],
      "metadata": {
        "id": "mTwLiy-cHx8z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from typing import TypedDict, Annotated\n",
        "import operator\n",
        "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
        "from IPython.display import Image\n",
        "import json\n",
        "from langchain_core.runnables.graph import MermaidDrawMethod\n",
        "\n",
        "#An Agent State class that keep state of the agent while it answers a query\n",
        "class OrdersAgentState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], operator.add]\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "#An agent class that manages all agentic interactions\n",
        "class OrdersAgent:\n",
        "\n",
        "    #Setup the agent graph, tools and memory\n",
        "    def __init__(self, model, tools, system_prompt, debug):\n",
        "\n",
        "        self.system_prompt=system_prompt\n",
        "        self.debug=debug\n",
        "\n",
        "        #Setup the graph for the agent manually\n",
        "        agent_graph=StateGraph(OrdersAgentState)\n",
        "        agent_graph.add_node(\"orders_llm\",self.call_llm)\n",
        "        agent_graph.add_node(\"orders_tools\",self.call_tools)\n",
        "        agent_graph.add_conditional_edges(\n",
        "            \"orders_llm\",\n",
        "            self.is_tool_call,\n",
        "            {True: \"orders_tools\", False: END }\n",
        "        )\n",
        "        agent_graph.add_edge(\"orders_tools\",\"orders_llm\")\n",
        "        #Set where there graph starts\n",
        "        agent_graph.set_entry_point(\"orders_llm\")\n",
        "\n",
        "        #Add chat memory\n",
        "        self.memory=MemorySaver()\n",
        "        #compile the graph\n",
        "        self.agent_graph = agent_graph.compile(checkpointer=self.memory)\n",
        "\n",
        "        #Setup tools\n",
        "        self.tools = { tool.name : tool for tool in tools }\n",
        "        if self.debug:\n",
        "            print(\"\\nTools loaded :\", self.tools)\n",
        "\n",
        "        #attach tools to model\n",
        "        self.model=model.bind_tools(tools)\n",
        "\n",
        "\n",
        "    #Call the LLM with the messages to get next action/result\n",
        "    def call_llm(self, state:OrdersAgentState):\n",
        "\n",
        "        messages=state[\"messages\"]\n",
        "\n",
        "        #If system prompt exists, add to messages in the front\n",
        "        if self.system_prompt:\n",
        "            messages = [SystemMessage(content=self.system_prompt)] + messages\n",
        "\n",
        "        #invoke the model with the message history\n",
        "        result = self.model.invoke(messages)\n",
        "        if self.debug:\n",
        "            print(f\"\\nLLM Returned : {result}\")\n",
        "        #Return the LLM output\n",
        "        return { \"messages\":[result] }\n",
        "\n",
        "\n",
        "    #Check if the next action is a tool call.\n",
        "    def is_tool_call(self, state:OrdersAgentState):\n",
        "        last_message = state[\"messages\"][-1]\n",
        "        #print(\"Last result from LLM : \", last_message)\n",
        "        #If tool action is requested\n",
        "        if len(last_message.tool_calls) > 0 :\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    #Execute the tool requested with the given parameters\n",
        "    def call_tools(self, state:OrdersAgentState):\n",
        "        #Get last message\n",
        "        tool_calls = state[\"messages\"][-1].tool_calls\n",
        "        results=[]\n",
        "\n",
        "        #Multiple tool calls may be requested. Execute one by one\n",
        "        for tool in tool_calls:\n",
        "            #Handle tool missing error\n",
        "            if not tool[\"name\"] in self.tools:\n",
        "                print(f\"Unknown tool name {tool}\")\n",
        "                result = \"Invalid tool found. Please retry\"\n",
        "            else:\n",
        "                #Call the tool and collect results\n",
        "                result=self.tools[tool[\"name\"]].invoke(tool[\"args\"])\n",
        "\n",
        "            #append results to the list of tool results\n",
        "            results.append(ToolMessage(tool_call_id=tool['id'],\n",
        "                                       name=tool['name'],\n",
        "                                       content=str(result)))\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"\\nTools returned {results}\")\n",
        "            #return tool results\n",
        "            return { \"messages\" : results }\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "#Setup the custom orders agent\n",
        "\n",
        "#Note that this is a string, since the model init only accepts a string.\n",
        "system_prompt = \"\"\"\n",
        "    You are professional chatbot that manages orders for laptops sold by our company.\n",
        "    The tools allow for retrieving order details as well as update order quantity.\n",
        "    Do NOT reveal information about other orders than the one requested.\n",
        "    You will handle small talk and greetings by producing professional responses.\n",
        "    \"\"\"\n",
        "\n",
        "#Create the custom orders agent\n",
        "orders_agent = OrdersAgent(model,\n",
        "                           [get_order_details, update_quantity],\n",
        "                           system_prompt,\n",
        "                           debug=False)\n",
        "\n",
        "#Visualize the Agent\n",
        "#Image(orders_agent.agent_graph.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.PYPPETEER))"
      ],
      "metadata": {
        "id": "8D3CiNRMINkB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "#Send a sequence of messages to chatbot and get its response\n",
        "#This simulates the conversation between the user and the Agentic chatbot\n",
        "user_inputs = [\n",
        "    \"How are you doing?\",\n",
        "    \"Please show me the details of the order ORD-7311\",\n",
        "    \"Can you add one more of that laptop to the order? \",\n",
        "    \"Can you show me the details again ? \",\n",
        "    \"What about order ORD-9999 ?\",\n",
        "    \"Bye\"\n",
        "]\n",
        "\n",
        "#Create a new thread\n",
        "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
        "\n",
        "for input in user_inputs:\n",
        "    print(f\"----------------------------------------\\nUSER : {input}\")\n",
        "    #Format the user message\n",
        "    user_message = {\"messages\":[HumanMessage(input)]}\n",
        "    #Get response from the agent\n",
        "    ai_response = orders_agent.agent_graph.invoke(user_message,config=config)\n",
        "    #Print the response\n",
        "    print(f\"\\nAGENT : {ai_response['messages'][-1].content}\")"
      ],
      "metadata": {
        "id": "_vL01VgcJpTR",
        "outputId": "544522c7-5ceb-47af-9297-c0c70cd23ef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "USER : How are you doing?\n",
            "\n",
            "AGENT : I'm here and ready to assist you with your laptop orders. How can I help you today?\n",
            "----------------------------------------\n",
            "USER : Please show me the details of the order ORD-7311\n",
            "\n",
            "AGENT : Here are the details for order **ORD-7311**:\n",
            "\n",
            "- **Product Ordered:** NanoEdge Flex\n",
            "- **Quantity Ordered:** 2\n",
            "- **Delivery Date:** 2024-10-19\n",
            "\n",
            "If you need any further assistance, feel free to ask!\n",
            "----------------------------------------\n",
            "USER : Can you add one more of that laptop to the order? \n",
            "\n",
            "AGENT : The quantity for order **ORD-7311** has been successfully updated to 3. If you need any more help, feel free to let me know!\n",
            "----------------------------------------\n",
            "USER : Can you show me the details again ? \n",
            "\n",
            "AGENT : Here are the updated details for order **ORD-7311**:\n",
            "\n",
            "- **Product Ordered:** NanoEdge Flex\n",
            "- **Quantity Ordered:** 3\n",
            "- **Delivery Date:** 2024-10-19\n",
            "\n",
            "If there's anything else you need, feel free to ask!\n",
            "----------------------------------------\n",
            "USER : What about order ORD-9999 ?\n",
            "\n",
            "AGENT : I'm sorry, but I couldn't find any details for order **ORD-9999**. Please check the order ID and let me know if there's anything else I can assist you with!\n",
            "----------------------------------------\n",
            "USER : Bye\n",
            "\n",
            "AGENT : Thank you for reaching out. Have a great day! If you need further assistance, feel free to contact us again. Goodbye!\n"
          ]
        }
      ]
    }
  ]
}